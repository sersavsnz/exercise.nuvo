from langchain.prompts import PipelinePromptTemplate, PromptTemplate
from langchain_openai import OpenAI

import conf


class Text2Code:
    """
    Text-to-code class generates a React function based on the user requirements.
    Users can complement the requirements with examples.

    The code is generated by the LLM of choice. Users instructions are injected in the full prompt.

    Todo:
    - extend code for:
        - choice of a programming language; currently supports only React (this would require changes in prompt templates)
        - datahandler functions
    Try:
    - other LLMs; current support only for openai; worth to look at open-source llms, the one from deepseek looks promising

    """

    def __init__(self, api_key: str):
        # init the LLM; given instructions it will generate code.
        self.api_key = api_key
        self.llm = OpenAI(openai_api_key=api_key)

    def init_prompt(self) -> None:
        """
        Init the prompts to pass to the LLM for code generation.
        The prompt is combined from various templates, containing different instructions and/or examples.
        To ensure more flexibility and customization, the LangChain's PipelinePromptTemplate is used.
        """
        full_template = conf.PROMPTS["FULL_TEMPLATE"]
        role_template = conf.PROMPTS["ROLE_TEMPLATE"]
        instruction_template = conf.PROMPTS["INSTRUCTION_TEMPLATE"]
        example_template = conf.PROMPTS["EXAMPLE_TEMPLATE"]
        start_template = conf.PROMPTS["START_TEMPLATE"]

        full_prompt = PromptTemplate.from_template(full_template)
        role_prompt = PromptTemplate.from_template(role_template)
        instruction_prompt = PromptTemplate.from_template(instruction_template)
        example_prompt = PromptTemplate.from_template(example_template)
        start_prompt = PromptTemplate.from_template(start_template)

        input_prompts = [
            ("role", role_prompt),
            ("instruction", instruction_prompt),
            ("example", example_prompt),
            ("start", start_prompt),
        ]

        self.prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)

    def init_llm_chain(self) -> None:
        """
        Init a Chain. Chain is a LangChain's core concept, similar to a pipeline.
        We form a chain by combining the prompt and an LLM used for generation.
        """
        self.init_prompt()
        self.llm_chain = self.prompt | self.llm

    def generate_code(self, user_input: list[str]) -> str:
        """
        Generates a React cleaning function given users instructions.

        Requires self.llm_chain to be initialized.
        """
        result = self.llm_chain.invoke(
            {
                "user_instruction": user_input["user_instruction"],
                "user_example": user_input["user_example"],
            }
        )
        return result

    def init_prompt_and_generate_code(self, user_input: list[str]) -> str:
        """
        Generates a React cleaning function given users instructions.

        First initializes the LLM prompt and then generates code.
        """
        self.init_llm_chain()
        return self.generate_code(user_input)
